{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle environment and install packages accordingly\n",
    "import sys\n",
    "if 'kaggle' in sys.modules:\n",
    "    !pip install openai-whisper pyannote.audio gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pyannote.audio.pipelines import SpeakerDiarization\n",
    "from pyannote.core import Segment\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# Handle Google Drive differently based on environment\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    audio_folder_path = \"/content/drive/MyDrive/Transcribe\"  # Update this path as per your folder structure\n",
    "    log_file_path = \"/content/drive/MyDrive/Transcribe/transcription_log.txt\"\n",
    "elif 'kaggle' in sys.modules:\n",
    "    # In Kaggle, use the default working directory or specify your own\n",
    "    audio_folder_path = \"/kaggle/input/your-audio-files-folder\"  # Replace with your folder name in Kaggle\n",
    "    log_file_path = \"/kaggle/working/transcription_log.txt\"\n",
    "else:\n",
    "    # For local environments\n",
    "    audio_folder_path = \"./Transcribe\"  # Local directory\n",
    "    log_file_path = \"./transcription_log.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "model_size = \"small\"  # Adjust based on your requirement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_message(message, log_file=log_file_path):\n",
    "    with open(log_file, \"a\") as file:\n",
    "        file.write(f\"{message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_and_log_full_transcript(audio_path, model, log_file=log_file_path):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = model.transcribe(audio_path)\n",
    "        execution_time = time.time() - start_time\n",
    "        success_message = f\"Transcription successful for {Path(audio_path).name}! Execution time: {execution_time:.2f} seconds\"\n",
    "        log_message(success_message, log_file)\n",
    "        \n",
    "        output_file_path = Path(audio_path).with_suffix('.txt')\n",
    "        with open(output_file_path, \"w\") as file:\n",
    "            for segment in result['segments']:\n",
    "                file.write(f\"{segment['start']}-{segment['end']}: {segment['text']}\\n\")\n",
    "        \n",
    "        log_message(f\"Full transcription saved to {output_file_path}\", log_file)\n",
    "        return result['segments']\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during transcription of {Path(audio_path).name}: {str(e)}\"\n",
    "        log_message(error_message, log_file)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_diarization_pyannote(audio_path, output_log=\"diarization_pyannote_log.txt\"):\n",
    "    start_time = time.time()\n",
    "    pipeline = SpeakerDiarization(segmentation=\"pyannote/segmentation\", use_auth_token=HfFolder.get_token())\n",
    "    diarization = pipeline({'uri': 'SpeakerDiarization', 'audio': audio_path})\n",
    "    \n",
    "    with open(output_log, \"w\") as log_file:\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            start, end = turn.start, turn.end\n",
    "            log_file.write(f\"Speaker: {speaker}, Start: {start}, End: {end}\\n\")\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"Diarization completed successfully in {execution_time:.2f} seconds.\")\n",
    "    return [{'speaker': speaker, 'start': turn.start, 'end': turn.end} for turn, _, speaker in diarization.itertracks(yield_label=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_diarization_with_transcript(diarization_results, transcription_segments):\n",
    "    integrated_output = []\n",
    "    for segment in transcription_segments:\n",
    "        speaker_label = \"Unknown\"\n",
    "        for speaker_segment in diarization_results:\n",
    "            if segment['start'] >= speaker_segment['start'] and segment['end'] <= speaker_segment['end']:\n",
    "                speaker_label = speaker_segment['speaker']\n",
    "                break\n",
    "        integrated_output.append(f\"{speaker_label}: {segment['text']}\")\n",
    "    return integrated_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_in_directory(directory_path, model):\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith(('.mp3', '.mp4', '.wav')):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            try:\n",
    "                transcription_segments = transcribe_and_log_full_transcript(file_path, model)\n",
    "                diarization_results = perform_diarization_pyannote(file_path)\n",
    "                integrated_transcript = integrate_diarization_with_transcript(diarization_results, transcription_segments)\n",
    "                \n",
    "                output_file_path = Path(file_path).with_suffix('.integrated.txt')\n",
    "                with open(output_file_path, \"w\") as file:\n",
    "                    for line in integrated_transcript:\n",
    "                        file.write(f\"{line}\\n\")\n",
    "                \n",
    "                print(f\"Integrated transcription saved to {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files_in_directory(audio_folder_path, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNpTNsCDYt6IEGL0VA1vZ5I",
   "gpuType": "T4",
   "mount_file_id": "1wk9qOfZK06RLBTEuy503MkQLIMNLmHXP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
